{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os.path as op\n",
    "import retro\n",
    "from src.features.annotations import generate_key_events, generate_aps_events, plot_bidsevents\n",
    "from src.features.features import compute_framewise_aps\n",
    "import matplotlib.pyplot as plt\n",
    "from src.params import figures_path\n",
    "from nilearn import plotting\n",
    "from nilearn import image\n",
    "import os\n",
    "import numpy as np\n",
    "from nilearn.plotting import plot_design_matrix\n",
    "import load_confounds\n",
    "from nilearn.input_data import NiftiMasker\n",
    "from nilearn.glm.first_level import FirstLevelModel\n",
    "\n",
    "# This is a modified version of src.data.data.retrieve_variables, adapted to the naming of scan-related behavioural files\n",
    "def retrieve_variables(files):\n",
    "    '''\n",
    "    files : list of files with complete path\n",
    "\n",
    "    variable_lists : dictionnary (each variable is an entry) containing list of arrays of\n",
    "    length corresponding to the number of frames in each run,\n",
    "    with runs ordered by timestamp.\n",
    "    '''\n",
    "\n",
    "    variables_lists = {}\n",
    "\n",
    "    for file in files:\n",
    "        level = file[-11:-8]\n",
    "        timestamp = file[-73:-65]\n",
    "        print(file)\n",
    "        if level == '5-0':\n",
    "            env = retro.make('ShinobiIIIReturnOfTheNinjaMaster-Genesis', state='Level5')\n",
    "        else:\n",
    "            env = retro.make('ShinobiIIIReturnOfTheNinjaMaster-Genesis', state='Level'+level)\n",
    "        actions = env.buttons\n",
    "\n",
    "        run_variables = {}\n",
    "        key_log = retro.Movie(file)\n",
    "        env.reset()\n",
    "        run_completed = False\n",
    "        while key_log.step():\n",
    "            a = [key_log.get_key(i, 0) for i in range(env.num_buttons)]\n",
    "            _,_,done,i = env.step(a)\n",
    "\n",
    "            if variables_lists == {}: # init final dict\n",
    "                variables_lists['filename'] = []\n",
    "                variables_lists['timestamp'] = []\n",
    "                variables_lists['level'] = []\n",
    "                for action in actions:\n",
    "                    variables_lists[action] = []\n",
    "                for variable in i.keys():\n",
    "                    variables_lists[variable] = []\n",
    "\n",
    "            if run_variables == {}: # init temp dict\n",
    "                for variable in i.keys():\n",
    "                    run_variables[variable] = []\n",
    "                for action in actions:\n",
    "                    run_variables[action] = []\n",
    "\n",
    "            for variable in i.keys(): # fill up temp dict\n",
    "                run_variables[variable].append(i[variable])\n",
    "            for idx_a, action in enumerate(actions):\n",
    "                run_variables[action].append(a[idx_a])\n",
    "\n",
    "            if done == True:\n",
    "                run_completed = True\n",
    "        variables_lists['filename'].append(file)\n",
    "        variables_lists['timestamp'].append(timestamp)\n",
    "        variables_lists['level'].append(level)\n",
    "\n",
    "        for variable in run_variables.keys():\n",
    "            variables_lists[variable].append(run_variables[variable])\n",
    "        env.close()\n",
    "    return variables_lists\n",
    "\n",
    "\n",
    "# This will go in src.features.annotations\n",
    "def create_runevents(runvars, startevents, actions, FS=60, min_dur=1, get_aps=True, get_actions=True):\n",
    "    onset_reps = startevents['onset'].values.tolist()\n",
    "    dur_reps = startevents['duration'].values.tolist()\n",
    "    lvl_reps = [x[-11] for x in startevents['stim_file'].values.tolist()]\n",
    "    \n",
    "    if get_aps:\n",
    "        framewise_aps = compute_framewise_aps(runvars, actions=actions, FS=FS)\n",
    "\n",
    "    # init df list\n",
    "    all_df = []\n",
    "\n",
    "    for idx, onset_rep in enumerate(onset_reps):\n",
    "        print('Extracting events for {}'.format(runvars['filename'][idx]))\n",
    "        if get_actions:\n",
    "            # get the different possible actions\n",
    "            # generate events for each of them\n",
    "            for act in actions:\n",
    "                var = runvars[act][idx]\n",
    "                temp_df = generate_key_events(var, act, FS=FS)\n",
    "                temp_df['onset'] = temp_df['onset'] + onset_rep\n",
    "                temp_df['trial_type'] = lvl_reps[idx] + '_' + temp_df['trial_type']\n",
    "                all_df.append(temp_df)\n",
    "        if get_aps:\n",
    "            temp_df = generate_aps_events(framewise_aps[idx], FS=FS)\n",
    "            temp_df['onset'] = temp_df['onset'] + onset_rep\n",
    "            temp_df['trial_type'] = lvl_reps[idx] + '_' + temp_df['trial_type']\n",
    "            all_df.append(temp_df)\n",
    "\n",
    "    events_df = pd.concat(all_df).sort_values(by='onset').reset_index(drop=True)\n",
    "    return events_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set constants for single subject, single run\n",
    "sub = 'sub-01'\n",
    "ses = 'ses-008'\n",
    "run = '1'\n",
    "actions = ['B', 'A', 'MODE', 'START', 'UP', 'DOWN', 'LEFT', 'RIGHT', 'C', 'Y', 'X', 'Z']\n",
    "dpath = '/media/hyruuk/Seagate Expansion Drive/DATA/data/shinobi/'\n",
    "events_fname = dpath + '{}/{}/func/{}_{}_task-shinobi_run-0{}_events.tsv'.format(sub, ses, sub, ses, run)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/hyruuk/Seagate Expansion Drive/DATA/data/shinobi/sourcedata/sub-01/ses-shinobi_008/sub-01_ses-shinobi_008_20201113-104817_ShinobiIIIReturnOfTheNinjaMaster-Genesis_Level1-0_000.bk2\n",
      "/media/hyruuk/Seagate Expansion Drive/DATA/data/shinobi/sourcedata/sub-01/ses-shinobi_008/sub-01_ses-shinobi_008_20201113-104817_ShinobiIIIReturnOfTheNinjaMaster-Genesis_Level4-1_000.bk2\n",
      "/media/hyruuk/Seagate Expansion Drive/DATA/data/shinobi/sourcedata/sub-01/ses-shinobi_008/sub-01_ses-shinobi_008_20201113-104817_ShinobiIIIReturnOfTheNinjaMaster-Genesis_Level5-0_000.bk2\n",
      "/media/hyruuk/Seagate Expansion Drive/DATA/data/shinobi/sourcedata/sub-01/ses-shinobi_008/sub-01_ses-shinobi_008_20201113-104817_ShinobiIIIReturnOfTheNinjaMaster-Genesis_Level1-0_001.bk2\n",
      "Extracting events for /media/hyruuk/Seagate Expansion Drive/DATA/data/shinobi/sourcedata/sub-01/ses-shinobi_008/sub-01_ses-shinobi_008_20201113-104817_ShinobiIIIReturnOfTheNinjaMaster-Genesis_Level1-0_000.bk2\n",
      "Extracting events for /media/hyruuk/Seagate Expansion Drive/DATA/data/shinobi/sourcedata/sub-01/ses-shinobi_008/sub-01_ses-shinobi_008_20201113-104817_ShinobiIIIReturnOfTheNinjaMaster-Genesis_Level4-1_000.bk2\n",
      "Extracting events for /media/hyruuk/Seagate Expansion Drive/DATA/data/shinobi/sourcedata/sub-01/ses-shinobi_008/sub-01_ses-shinobi_008_20201113-104817_ShinobiIIIReturnOfTheNinjaMaster-Genesis_Level5-0_000.bk2\n",
      "Extracting events for /media/hyruuk/Seagate Expansion Drive/DATA/data/shinobi/sourcedata/sub-01/ses-shinobi_008/sub-01_ses-shinobi_008_20201113-104817_ShinobiIIIReturnOfTheNinjaMaster-Genesis_Level1-0_001.bk2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hyruuk/anaconda3/envs/hyruuk_shinobi_behav/lib/python3.8/site-packages/sklearn/preprocessing/_data.py:174: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting a GLM\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Data given cannot be loaded because it is not compatible with nibabel format:\n94.041466",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-7e163a3ef22f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     60\u001b[0m                            \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                            smoothing_fwhm=5)\n\u001b[0;32m---> 62\u001b[0;31m \u001b[0mfmri_glm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfmri_glm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasked_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLvR_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/hyruuk_shinobi_behav/lib/python3.8/site-packages/nilearn/glm/first_level/first_level.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, run_imgs, events, confounds, design_matrices)\u001b[0m\n\u001b[1;32m    405\u001b[0m                                        \u001b[0mmemory_level\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory_level\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m                                        )\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasker_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_imgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask_img_\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasker_\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hyruuk_shinobi_behav/lib/python3.8/site-packages/nilearn/input_data/nifti_masker.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, imgs, y)\u001b[0m\n\u001b[1;32m    328\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[%s.fit] Computing the mask\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m             self.mask_img_ = self._cache(compute_mask, ignore=['verbose'])(\n\u001b[0m\u001b[1;32m    331\u001b[0m                 imgs, verbose=max(0, self.verbose - 1), **mask_args)\n\u001b[1;32m    332\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hyruuk_shinobi_behav/lib/python3.8/site-packages/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hyruuk_shinobi_behav/lib/python3.8/site-packages/nilearn/masking.py\u001b[0m in \u001b[0;36mcompute_epi_mask\u001b[0;34m(epi_img, lower_cutoff, upper_cutoff, connected, opening, exclude_zeros, ensure_finite, target_affine, target_shape, memory, verbose)\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_compute_mean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0mmean_epi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maffine\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m         cache(_compute_mean, memory)(epi_img, target_affine=target_affine,\n\u001b[0m\u001b[1;32m    266\u001b[0m                                      \u001b[0mtarget_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m                                      smooth=(1 if opening else False))\n",
      "\u001b[0;32m~/anaconda3/envs/hyruuk_shinobi_behav/lib/python3.8/site-packages/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hyruuk_shinobi_behav/lib/python3.8/site-packages/nilearn/image/image.py\u001b[0m in \u001b[0;36m_compute_mean\u001b[0;34m(imgs, target_affine, target_shape, smooth)\u001b[0m\n\u001b[1;32m    470\u001b[0m     \u001b[0minput_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_repr_niimgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m     \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_niimg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m     \u001b[0mmean_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_safe_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m     \u001b[0maffine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maffine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hyruuk_shinobi_behav/lib/python3.8/site-packages/nilearn/_utils/niimg_conversions.py\u001b[0m in \u001b[0;36mcheck_niimg\u001b[0;34m(niimg, ensure_ndim, atleast_4d, dtype, return_iterator, wildcards)\u001b[0m\n\u001b[1;32m    258\u001b[0m             return _iter_check_niimg(niimg, ensure_ndim=ensure_ndim,\n\u001b[1;32m    259\u001b[0m                                      dtype=dtype)\n\u001b[0;32m--> 260\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mconcat_niimgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mniimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_ndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_ndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;31m# Otherwise, it should be a filename or a SpatialImage, we load it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hyruuk_shinobi_behav/lib/python3.8/site-packages/nilearn/_utils/niimg_conversions.py\u001b[0m in \u001b[0;36mconcat_niimgs\u001b[0;34m(niimgs, dtype, ensure_ndim, memory, memory_level, auto_resample, verbose)\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mliterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtee\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mniimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m         \u001b[0mfirst_niimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_niimg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mliterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_ndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot concatenate empty objects'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hyruuk_shinobi_behav/lib/python3.8/site-packages/nilearn/_utils/niimg_conversions.py\u001b[0m in \u001b[0;36mcheck_niimg\u001b[0;34m(niimg, ensure_ndim, atleast_4d, dtype, return_iterator, wildcards)\u001b[0m\n\u001b[1;32m    258\u001b[0m             return _iter_check_niimg(niimg, ensure_ndim=ensure_ndim,\n\u001b[1;32m    259\u001b[0m                                      dtype=dtype)\n\u001b[0;32m--> 260\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mconcat_niimgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mniimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_ndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_ndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;31m# Otherwise, it should be a filename or a SpatialImage, we load it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hyruuk_shinobi_behav/lib/python3.8/site-packages/nilearn/_utils/niimg_conversions.py\u001b[0m in \u001b[0;36mconcat_niimgs\u001b[0;34m(niimgs, dtype, ensure_ndim, memory, memory_level, auto_resample, verbose)\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mliterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtee\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mniimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m         \u001b[0mfirst_niimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_niimg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mliterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_ndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot concatenate empty objects'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hyruuk_shinobi_behav/lib/python3.8/site-packages/nilearn/_utils/niimg_conversions.py\u001b[0m in \u001b[0;36mcheck_niimg\u001b[0;34m(niimg, ensure_ndim, atleast_4d, dtype, return_iterator, wildcards)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;31m# Otherwise, it should be a filename or a SpatialImage, we load it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m     \u001b[0mniimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_niimg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mniimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_ndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mniimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mniimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hyruuk_shinobi_behav/lib/python3.8/site-packages/nilearn/_utils/niimg.py\u001b[0m in \u001b[0;36mload_niimg\u001b[0;34m(niimg, dtype)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mniimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnibabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mniimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mniimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnibabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspatialimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSpatialImage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         raise TypeError(\"Data given cannot be loaded because it is\"\n\u001b[0m\u001b[1;32m    122\u001b[0m                         \u001b[0;34m\" not compatible with nibabel format:\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m                         + short_repr(niimg))\n",
      "\u001b[0;31mTypeError\u001b[0m: Data given cannot be loaded because it is not compatible with nibabel format:\n94.041466"
     ]
    }
   ],
   "source": [
    "# Obtain list of bk2 files from events\n",
    "startevents = pd.read_table(events_fname)\n",
    "files = startevents['stim_file'].values.tolist()\n",
    "files = [dpath + file for file in files]\n",
    "\n",
    "# Retrieve variables from these files\n",
    "runvars = retrieve_variables(files)\n",
    "events_df = create_runevents(runvars, startevents, actions=actions)\n",
    "events_df['trial_type'].unique()\n",
    "\n",
    "# Create LvR_df\n",
    "lh_df = pd.concat([events_df[events_df['trial_type'] == '1_LEFT'], \n",
    "                   events_df[events_df['trial_type'] == '1_RIGHT'],\n",
    "                   events_df[events_df['trial_type'] == '1_DOWN'],\n",
    "                   events_df[events_df['trial_type'] == '1_UP'],\n",
    "                   events_df[events_df['trial_type'] == '4_LEFT'], \n",
    "                   events_df[events_df['trial_type'] == '4_RIGHT'],\n",
    "                   events_df[events_df['trial_type'] == '4_DOWN'],\n",
    "                   events_df[events_df['trial_type'] == '4_UP'],\n",
    "                    events_df[events_df['trial_type'] == '5_LEFT'], \n",
    "                   events_df[events_df['trial_type'] == '5_RIGHT'],\n",
    "                   events_df[events_df['trial_type'] == '5_DOWN'],\n",
    "                   events_df[events_df['trial_type'] == '5_UP']\n",
    "                  ]).sort_values(by='onset').reset_index(drop=True)\n",
    "lh_df['trial_type'] = 'LeftH'\n",
    "\n",
    "rh_df = pd.concat([events_df[events_df['trial_type'] == '1_B'], \n",
    "                   events_df[events_df['trial_type'] == '1_C'],\n",
    "                   events_df[events_df['trial_type'] == '4_B'], \n",
    "                   events_df[events_df['trial_type'] == '4_C'],\n",
    "                    events_df[events_df['trial_type'] == '5_B'], \n",
    "                   events_df[events_df['trial_type'] == '5_C']\n",
    "                  ]).sort_values(by='onset').reset_index(drop=True)\n",
    "rh_df['trial_type'] = 'RightH'\n",
    "\n",
    "LvR_df = pd.concat([lh_df, rh_df]).sort_values(by='onset').reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Build Nifti file name\n",
    "filename = dpath + 'derivatives/fmriprep-20.2lts/fmriprep/{}/{}/func/sub-01_ses-008_task-shinobi_run-{}_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz'.format(sub, ses, run)\n",
    "confounds_fname = dpath + 'derivatives/fmriprep-20.2lts/fmriprep/{}/{}/func/sub-01_{}_task-shinobi_run-{}_desc-confounds_timeseries.tsv'.format(sub, ses, ses, run)\n",
    "\n",
    "# Load and concat 3d images\n",
    "fmri_img = image.concat_imgs(filename)\n",
    "\n",
    "# Load and fit confounds\n",
    "confounds = load_confounds.Params36().load(confounds_fname)\n",
    "masker = NiftiMasker()\n",
    "masker = masker.fit(fmri_img)\n",
    "masked_img = masker.transform(fmri_img, confounds=confounds)\n",
    "\n",
    "# Fit the GLM\n",
    "print('Fitting a GLM')\n",
    "fmri_glm = FirstLevelModel(t_r=1.49,\n",
    "                           noise_model='ar1',\n",
    "                           standardize=False,\n",
    "                           hrf_model='spm',\n",
    "                           drift_model='cosine',\n",
    "                           high_pass=.01,\n",
    "                           n_jobs=-1,\n",
    "                           smoothing_fwhm=5)\n",
    "fmri_glm = fmri_glm.fit(masked_img, LvR_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confounds = load_confounds.Params36().load(confounds_fname)\n",
    "masker = NiftiMasker()\n",
    "masker = masker.fit(fmri_img)\n",
    "masked_img = masker.transform(fmri_img, confounds=confounds)\n",
    "fmri_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build GLM\n",
    "from nilearn.glm.first_level import FirstLevelModel\n",
    "fmri_glm = FirstLevelModel(t_r=1.49,\n",
    "                           noise_model='ar1',\n",
    "                           standardize=False,\n",
    "                           hrf_model='spm',\n",
    "                           drift_model='cosine',\n",
    "                           high_pass=.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit\n",
    "fmri_glm = fmri_glm.fit(fmri_img, LvR_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create design_matrix\n",
    "design_matrix = fmri_glm.design_matrices_[0]\n",
    "\n",
    "# Plot\n",
    "from nilearn.plotting import plot_design_matrix\n",
    "plot_design_matrix(design_matrix)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot convoluted regressors\n",
    "plt.plot(design_matrix['LeftH'], label='LeftH')\n",
    "plt.plot(design_matrix['RightH'], label='RightH')\n",
    "\n",
    "plt.xlabel('scan')\n",
    "plt.title('Expected BOLD response')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create condition arrays\n",
    "from numpy import array\n",
    "conditions = {\n",
    "    'LeftH': array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
    "    'RightH':   array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subtract conditions\n",
    "left_minus_right = conditions['LeftH'] - conditions['RightH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot contrast\n",
    "from nilearn.plotting import plot_contrast_matrix\n",
    "plot_contrast_matrix(left_minus_right, design_matrix=design_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z score maps\n",
    "\n",
    "z_map = fmri_glm.compute_contrast(['LeftH-RightH'],\n",
    "                                    output_type='z_score', stat_type='F')\n",
    "plotting.plot_stat_map(z_map, bg_img=mean_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z threshold\n",
    "\n",
    "plotting.plot_stat_map(z_map, bg_img=mean_img, threshold=3.0,\n",
    "              display_mode='z', cut_coords=3, black_bg=True,\n",
    "              title='Left minus Right Hand (Z>3)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncorrected\n",
    "\n",
    "from nistats.thresholding import map_threshold\n",
    "uncorr_001, threshold = map_threshold(z_map, alpha=.001, height_control='fpr')\n",
    "print('Uncorrected p<0.001 threshold: %.3f' % threshold)\n",
    "plotting.plot_stat_map(z_map, bg_img=mean_img, threshold=threshold,\n",
    "              display_mode='z', cut_coords=3, black_bg=True,\n",
    "              title='Left minus Right Hand (p<0.001)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FDR only\n",
    "\n",
    "_, threshold = map_threshold(z_map, alpha=.05, height_control='fdr')\n",
    "\n",
    "print('Taux de fausse découverte (FDR) = 0.05 threshold: %.3f' % threshold)\n",
    "\n",
    "plotting.plot_stat_map(z_map, bg_img=mean_img, threshold=threshold,\n",
    "              display_mode='z', cut_coords=3, black_bg=True,\n",
    "              title='sub-01, ses-008, run-01, Left minus Right Hand (fdr=0.05)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FDR + clusters\n",
    "\n",
    "clean_map, threshold = map_threshold(z_map, alpha=.05, height_control='fdr', cluster_threshold=10)\n",
    "\n",
    "plotting.plot_stat_map(clean_map, bg_img=mean_img, threshold=threshold,\n",
    "              display_mode='z', cut_coords=3, black_bg=True,\n",
    "              title='Left minus Right Hand (FDR=0.05), Noyaux > 10 voxels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save interactive plot\n",
    "view = plotting.view_img(clean_map, threshold=3, title='Left minus Right Hand (FDR=0.05), Noyaux > 10 voxels')\n",
    "view.save_as_html(figures_path + '/LmR_statsmap.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set constants for MULTIPLE RUNS\n",
    "sub = 'sub-01'\n",
    "actions = ['B', 'A', 'MODE', 'START', 'UP', 'DOWN', 'LEFT', 'RIGHT', 'C', 'Y', 'X', 'Z']\n",
    "dpath = '/media/hyruuk/Seagate Expansion Drive/DATA/data/shinobi/'\n",
    "\n",
    "\n",
    "\n",
    "seslist= os.listdir(dpath + sub)\n",
    "\n",
    "allruns_events = []\n",
    "fmri_img = []\n",
    "for ses in ['ses-001']:#sorted(seslist):\n",
    "    runs = [filename[-13] for filename in os.listdir(dpath + '{}/{}/func'.format(sub, ses)) if 'bold.nii.gz' in filename]\n",
    "    print(runs)\n",
    "    for run in sorted(runs):\n",
    "        print('computing run {}'.format(run))\n",
    "        events_fname = dpath + '{}/{}/func/{}_{}_task-shinobi_run-0{}_events.tsv'.format(sub, ses, sub, ses, run)\n",
    "        filename = dpath + 'derivatives/fmriprep-20.2lts/fmriprep/{}/{}/func/sub-01_{}_task-shinobi_run-{}_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz'.format(sub, ses, ses, run)\n",
    "        confounds_fname = dpath + 'derivatives/fmriprep-20.2lts/fmriprep/{}/{}/func/sub-01_{}_task-shinobi_run-{}_desc-confounds_timeseries.tsv'.format(sub, ses, ses, run)\n",
    "        # Obtain list of bk2 files from events\n",
    "        startevents = pd.read_table(events_fname)\n",
    "        files = startevents['stim_file'].values.tolist()\n",
    "        files = [dpath + file for file in files]\n",
    "\n",
    "        # Retrieve variables from these files\n",
    "        runvars = retrieve_variables(files)\n",
    "        events_df = create_runevents(runvars, startevents, actions=actions)\n",
    "        events_df['trial_type'].unique()\n",
    "\n",
    "        # Create LvR_df\n",
    "        lh_df = pd.concat([events_df[events_df['trial_type'] == '1_LEFT'], \n",
    "                           events_df[events_df['trial_type'] == '1_RIGHT'],\n",
    "                           events_df[events_df['trial_type'] == '1_DOWN'],\n",
    "                           events_df[events_df['trial_type'] == '1_UP'],\n",
    "                           events_df[events_df['trial_type'] == '4_LEFT'], \n",
    "                           events_df[events_df['trial_type'] == '4_RIGHT'],\n",
    "                           events_df[events_df['trial_type'] == '4_DOWN'],\n",
    "                           events_df[events_df['trial_type'] == '4_UP'],\n",
    "                            events_df[events_df['trial_type'] == '5_LEFT'], \n",
    "                           events_df[events_df['trial_type'] == '5_RIGHT'],\n",
    "                           events_df[events_df['trial_type'] == '5_DOWN'],\n",
    "                           events_df[events_df['trial_type'] == '5_UP']\n",
    "                          ]).sort_values(by='onset').reset_index(drop=True)\n",
    "        lh_df['trial_type'] = 'LeftH'\n",
    "        rh_df = pd.concat([events_df[events_df['trial_type'] == '1_B'], \n",
    "                           events_df[events_df['trial_type'] == '1_C'],\n",
    "                           events_df[events_df['trial_type'] == '4_B'], \n",
    "                           events_df[events_df['trial_type'] == '4_C'],\n",
    "                            events_df[events_df['trial_type'] == '5_B'], \n",
    "                           events_df[events_df['trial_type'] == '5_C']\n",
    "                          ]).sort_values(by='onset').reset_index(drop=True)\n",
    "        rh_df['trial_type'] = 'RightH'\n",
    "        LvR_df = pd.concat([lh_df, rh_df]).sort_values(by='onset').reset_index(drop=True)\n",
    "        \n",
    "        allruns_events.append(LvR_df)\n",
    "        \n",
    "        confounds = load_confounds.Params36().load(confounds_fname)\n",
    "        masker = NiftiMasker()\n",
    "        masker.fit(filename)\n",
    "        \n",
    "        masked_img = masker.transform(filename, confounds=confounds)\n",
    "        fmri_img.append(masked_img)\n",
    "\n",
    "        \n",
    "#import pickle\n",
    "#with open(dpath + '{}_events_files.pkl'.format(sub), 'wb') as f:\n",
    "#    pickle.dump(allruns_events, f)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.glm.first_level import FirstLevelModel\n",
    "print('Fitting a GLM')\n",
    "fmri_glm = FirstLevelModel(t_r=1.49,\n",
    "                           noise_model='ar1',\n",
    "                           standardize=False,\n",
    "                           hrf_model='spm',\n",
    "                           drift_model='cosine',\n",
    "                           high_pass=.01,\n",
    "                           n_jobs=-1,\n",
    "                           smoothing_fwhm=5)\n",
    "fmri_glm = fmri_glm.fit(fmri_img, allruns_events)\n",
    "\n",
    "\n",
    "mean_img = image.mean_img(fmri_img)\n",
    "plotting.plot_img(mean_img, title='Image de fond (T2* - BOLD)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_map = fmri_glm.compute_contrast(['LeftH-RightH'] * len(fmri_img), \n",
    "    output_type='z_score', stat_type='F')\n",
    "\n",
    "plotting.plot_stat_map(z_map, bg_img=mean_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nistats.thresholding import map_threshold\n",
    "\n",
    "clean_map, threshold = map_threshold(z_map, alpha=.05, height_control='fdr', cluster_threshold=10)\n",
    "uncorr_map, threshold = map_threshold(z_map, alpha=.001, height_control='fpr')\n",
    "\n",
    "\n",
    "plotting.plot_stat_map(clean_map, bg_img=mean_img, threshold=threshold,\n",
    "              display_mode='z', cut_coords=3, black_bg=True,\n",
    "              title='Left minus Right Hand (FDR=0.05), Noyaux > 10 voxels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view = plotting.view_img(clean_map, threshold=3, title='Left minus Right Hand (FDR=0.05), Noyaux > 10 voxels')\n",
    "view.save_as_html(figures_path + '/{}_LmR_statsmap_allruns_FDRcluster.html'.format(sub))\n",
    "\n",
    "view = plotting.view_img(clean_map, threshold=3, title='Left minus Right Hand (p<0.001), uncorr')\n",
    "view.save_as_html(figures_path + '/{}_LmR_statsmap_allruns_uncorr.html'.format(sub))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.plotting import plot_design_matrix\n",
    "plot_design_matrix(fmri_glm.design_matrices_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['LeftH-RightH'] * len(fmri_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bids import BIDSLayout\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpath = '/media/hyruuk/Seagate Expansion Drive/DATA/data/shinobi/derivatives/fmriprep-20.2lts/fmriprep'\n",
    "\n",
    "layout = BIDSLayout(dpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masker = NiftiMasker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = masker.transform(file, confounds=confounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hyruuk_shinobi_behav",
   "language": "python",
   "name": "hyruuk_shinobi_behav"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
