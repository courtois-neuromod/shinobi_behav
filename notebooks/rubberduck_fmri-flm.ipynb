{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and data loading\n",
    "The next three cells are pre-requisites to the later Nilearn cells, run them in order and adjust parameters in the second cell (especially dpath and anat_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os.path as op\n",
    "import retro\n",
    "from src.features.annotations import generate_key_events, generate_aps_events, plot_bidsevents\n",
    "from src.features.features import compute_framewise_aps\n",
    "import matplotlib.pyplot as plt\n",
    "from src.params import figures_path\n",
    "from nilearn import plotting\n",
    "from nilearn import image\n",
    "import os\n",
    "import numpy as np\n",
    "from nilearn.plotting import plot_design_matrix\n",
    "import load_confounds\n",
    "from nilearn.input_data import NiftiMasker\n",
    "from nilearn.glm.first_level import FirstLevelModel\n",
    "\n",
    "# This is a modified version of src.data.data.retrieve_variables, adapted to the naming of scan-related behavioural files\n",
    "def retrieve_variables(files):\n",
    "    '''\n",
    "    files : list of files with complete path\n",
    "\n",
    "    variable_lists : dictionnary (each variable is an entry) containing list of arrays of\n",
    "    length corresponding to the number of frames in each run,\n",
    "    with runs ordered by timestamp.\n",
    "    '''\n",
    "\n",
    "    variables_lists = {}\n",
    "\n",
    "    for file in files:\n",
    "        level = file[-11:-8]\n",
    "        timestamp = file[-73:-65]\n",
    "        print(file)\n",
    "        if level == '5-0':\n",
    "            env = retro.make('ShinobiIIIReturnOfTheNinjaMaster-Genesis', state='Level5')\n",
    "        else:\n",
    "            env = retro.make('ShinobiIIIReturnOfTheNinjaMaster-Genesis', state='Level'+level)\n",
    "        actions = env.buttons\n",
    "\n",
    "        run_variables = {}\n",
    "        key_log = retro.Movie(file)\n",
    "        env.reset()\n",
    "        run_completed = False\n",
    "        while key_log.step():\n",
    "            a = [key_log.get_key(i, 0) for i in range(env.num_buttons)]\n",
    "            _,_,done,i = env.step(a)\n",
    "\n",
    "            if variables_lists == {}: # init final dict\n",
    "                variables_lists['filename'] = []\n",
    "                variables_lists['timestamp'] = []\n",
    "                variables_lists['level'] = []\n",
    "                for action in actions:\n",
    "                    variables_lists[action] = []\n",
    "                for variable in i.keys():\n",
    "                    variables_lists[variable] = []\n",
    "\n",
    "            if run_variables == {}: # init temp dict\n",
    "                for variable in i.keys():\n",
    "                    run_variables[variable] = []\n",
    "                for action in actions:\n",
    "                    run_variables[action] = []\n",
    "\n",
    "            for variable in i.keys(): # fill up temp dict\n",
    "                run_variables[variable].append(i[variable])\n",
    "            for idx_a, action in enumerate(actions):\n",
    "                run_variables[action].append(a[idx_a])\n",
    "\n",
    "            if done == True:\n",
    "                run_completed = True\n",
    "        variables_lists['filename'].append(file)\n",
    "        variables_lists['timestamp'].append(timestamp)\n",
    "        variables_lists['level'].append(level)\n",
    "\n",
    "        for variable in run_variables.keys():\n",
    "            variables_lists[variable].append(run_variables[variable])\n",
    "        env.close()\n",
    "    return variables_lists\n",
    "\n",
    "\n",
    "# This will go in src.features.annotations\n",
    "def create_runevents(runvars, startevents, actions, FS=60, min_dur=1, get_aps=True, get_actions=True):\n",
    "    onset_reps = startevents['onset'].values.tolist()\n",
    "    dur_reps = startevents['duration'].values.tolist()\n",
    "    lvl_reps = [x[-11] for x in startevents['stim_file'].values.tolist()]\n",
    "    \n",
    "    if get_aps:\n",
    "        framewise_aps = compute_framewise_aps(runvars, actions=actions, FS=FS)\n",
    "\n",
    "    # init df list\n",
    "    all_df = []\n",
    "\n",
    "    for idx, onset_rep in enumerate(onset_reps):\n",
    "        print('Extracting events for {}'.format(runvars['filename'][idx]))\n",
    "        if get_actions:\n",
    "            # get the different possible actions\n",
    "            # generate events for each of them\n",
    "            for act in actions:\n",
    "                var = runvars[act][idx]\n",
    "                temp_df = generate_key_events(var, act, FS=FS)\n",
    "                temp_df['onset'] = temp_df['onset'] + onset_rep\n",
    "                temp_df['trial_type'] = lvl_reps[idx] + '_' + temp_df['trial_type']\n",
    "                all_df.append(temp_df)\n",
    "        if get_aps:\n",
    "            temp_df = generate_aps_events(framewise_aps[idx], FS=FS)\n",
    "            temp_df['onset'] = temp_df['onset'] + onset_rep\n",
    "            temp_df['trial_type'] = lvl_reps[idx] + '_' + temp_df['trial_type']\n",
    "            all_df.append(temp_df)\n",
    "\n",
    "    events_df = pd.concat(all_df).sort_values(by='onset').reset_index(drop=True)\n",
    "    return events_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set constants for single subject, single run\n",
    "sub = 'sub-01'\n",
    "ses = 'ses-008'\n",
    "run = '1'\n",
    "actions = ['B', 'A', 'MODE', 'START', 'UP', 'DOWN', 'LEFT', 'RIGHT', 'C', 'Y', 'X', 'Z']\n",
    "dpath = '/media/hyruuk/Seagate Expansion Drive/DATA/shinobi/'\n",
    "events_fname = dpath + '{}/{}/func/{}_{}_task-shinobi_run-0{}_events.tsv'.format(sub, ses, sub, ses, run)\n",
    "data_fname = dpath + 'derivatives/fmriprep-20.2lts/fmriprep/{}/{}/func/{}_{}_task-shinobi_run-{}_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz'.format(sub, ses, sub, ses, run)\n",
    "confounds_fname = dpath + 'derivatives/fmriprep-20.2lts/fmriprep/{}/{}/func/{}_{}_task-shinobi_run-{}_desc-confounds_timeseries.tsv'.format(sub, ses, sub, ses, run)\n",
    "anat_fname = '/media/hyruuk/Seagate Expansion Drive/DATA/anat/derivatives/fmriprep-20.2lts/fmriprep/{}/anat/{}_space-MNI152NLin2009cAsym_desc-brain_mask.nii.gz'.format(sub, sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/hyruuk/Seagate Expansion Drive/DATA/shinobi/sourcedata/sub-01/ses-shinobi_008/sub-01_ses-shinobi_008_20201113-104817_ShinobiIIIReturnOfTheNinjaMaster-Genesis_Level1-0_000.bk2\n",
      "/media/hyruuk/Seagate Expansion Drive/DATA/shinobi/sourcedata/sub-01/ses-shinobi_008/sub-01_ses-shinobi_008_20201113-104817_ShinobiIIIReturnOfTheNinjaMaster-Genesis_Level4-1_000.bk2\n",
      "/media/hyruuk/Seagate Expansion Drive/DATA/shinobi/sourcedata/sub-01/ses-shinobi_008/sub-01_ses-shinobi_008_20201113-104817_ShinobiIIIReturnOfTheNinjaMaster-Genesis_Level5-0_000.bk2\n",
      "/media/hyruuk/Seagate Expansion Drive/DATA/shinobi/sourcedata/sub-01/ses-shinobi_008/sub-01_ses-shinobi_008_20201113-104817_ShinobiIIIReturnOfTheNinjaMaster-Genesis_Level1-0_001.bk2\n",
      "Extracting events for /media/hyruuk/Seagate Expansion Drive/DATA/shinobi/sourcedata/sub-01/ses-shinobi_008/sub-01_ses-shinobi_008_20201113-104817_ShinobiIIIReturnOfTheNinjaMaster-Genesis_Level1-0_000.bk2\n",
      "Extracting events for /media/hyruuk/Seagate Expansion Drive/DATA/shinobi/sourcedata/sub-01/ses-shinobi_008/sub-01_ses-shinobi_008_20201113-104817_ShinobiIIIReturnOfTheNinjaMaster-Genesis_Level4-1_000.bk2\n",
      "Extracting events for /media/hyruuk/Seagate Expansion Drive/DATA/shinobi/sourcedata/sub-01/ses-shinobi_008/sub-01_ses-shinobi_008_20201113-104817_ShinobiIIIReturnOfTheNinjaMaster-Genesis_Level5-0_000.bk2\n",
      "Extracting events for /media/hyruuk/Seagate Expansion Drive/DATA/shinobi/sourcedata/sub-01/ses-shinobi_008/sub-01_ses-shinobi_008_20201113-104817_ShinobiIIIReturnOfTheNinjaMaster-Genesis_Level1-0_001.bk2\n"
     ]
    }
   ],
   "source": [
    "# Obtain list of bk2 files from events\n",
    "startevents = pd.read_table(events_fname)\n",
    "files = startevents['stim_file'].values.tolist()\n",
    "files = [dpath + file for file in files]\n",
    "\n",
    "# Retrieve variables from these files\n",
    "runvars = retrieve_variables(files)\n",
    "events_df = create_runevents(runvars, startevents, actions=actions)\n",
    "events_df['trial_type'].unique()\n",
    "\n",
    "# Create LvR_df\n",
    "lh_df = pd.concat([events_df[events_df['trial_type'] == '1_LEFT'], \n",
    "                   events_df[events_df['trial_type'] == '1_RIGHT'],\n",
    "                   events_df[events_df['trial_type'] == '1_DOWN'],\n",
    "                   events_df[events_df['trial_type'] == '1_UP'],\n",
    "                   events_df[events_df['trial_type'] == '4_LEFT'], \n",
    "                   events_df[events_df['trial_type'] == '4_RIGHT'],\n",
    "                   events_df[events_df['trial_type'] == '4_DOWN'],\n",
    "                   events_df[events_df['trial_type'] == '4_UP'],\n",
    "                    events_df[events_df['trial_type'] == '5_LEFT'], \n",
    "                   events_df[events_df['trial_type'] == '5_RIGHT'],\n",
    "                   events_df[events_df['trial_type'] == '5_DOWN'],\n",
    "                   events_df[events_df['trial_type'] == '5_UP']\n",
    "                  ]).sort_values(by='onset').reset_index(drop=True)\n",
    "lh_df['trial_type'] = 'LeftH'\n",
    "\n",
    "rh_df = pd.concat([events_df[events_df['trial_type'] == '1_B'], \n",
    "                   events_df[events_df['trial_type'] == '1_C'],\n",
    "                   events_df[events_df['trial_type'] == '4_B'], \n",
    "                   events_df[events_df['trial_type'] == '4_C'],\n",
    "                    events_df[events_df['trial_type'] == '5_B'], \n",
    "                   events_df[events_df['trial_type'] == '5_C']\n",
    "                  ]).sort_values(by='onset').reset_index(drop=True)\n",
    "rh_df['trial_type'] = 'RightH'\n",
    "\n",
    "LvR_df = pd.concat([lh_df, rh_df]).sort_values(by='onset').reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Load and concat 3d images\n",
    "fmri_img = image.concat_imgs(data_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analysis with Nilearn\n",
    "\n",
    "The correct files are now loaded and the events_df is created based on behavioural logs. We are ready to run some GLMs.\n",
    "\n",
    "Running a GLM on a single run without loading any confounds or anatomical mask is fairly easy. Running the same analysis with multiple runs is a bit computationally heavier, but the code is as straight-forward as for single runs (just append the fmri_imgs of the different runs in a list, and pass this list to glm.fit_transform instead of the single-run fmri_img, and do the same to pass events as a list of dataframes). \n",
    "\n",
    "However, there are three additional steps that I still need to implement in the pipeline :\n",
    "1. I need to use the anatomical image to create a mask that will have a higher spatial resolution than the mask automatically generated from functional images. Then, all fmri_imgs must be transformed with this mask so they keep the same shape.\n",
    "2. I need to take confounds into account, especially since movements are likely to be a key source of artifacts in a video game paradigm. \n",
    "3. I need to manually high-pass filter and normalize the hand regressors.\n",
    "\n",
    "Let's start with a bit of code that works, and then we shall see what doesn't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code that works\n",
    "fmri_glm = FirstLevelModel(t_r=1.49,\n",
    "                           noise_model='ar1',\n",
    "                           standardize=False,\n",
    "                           hrf_model='spm',\n",
    "                           drift_model='cosine',\n",
    "                           high_pass=.01,\n",
    "                           n_jobs=-1,\n",
    "                           smoothing_fwhm=5)\n",
    "\n",
    "fmri_glm = fmri_glm.fit(fmri_img, LvR_df) # for multiple runs, fmri_img and LvR_df are lists of NiftiImgs and DataFrames, respectively\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Data given cannot be loaded because it is not compatible with nibabel format:\nNiftiMasker(mask_i...",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-f8241dad5e47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Since that worked, let's treat ourselves a quick report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfmri_glm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontrasts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'LeftH-RightH'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/hyruuk_shinobi_behav/lib/python3.8/site-packages/nilearn/glm/_base.py\u001b[0m in \u001b[0;36mgenerate_report\u001b[0;34m(self, contrasts, title, bg_img, threshold, alpha, cluster_threshold, height_control, min_distance, plot_type, display_mode, report_dims)\u001b[0m\n\u001b[1;32m    105\u001b[0m         \"\"\"\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mnilearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreporting\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmake_glm_report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         return make_glm_report(\n\u001b[0m\u001b[1;32m    108\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontrasts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbg_img\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbg_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcluster_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcluster_threshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hyruuk_shinobi_behav/lib/python3.8/site-packages/nilearn/reporting/glm_reporter.py\u001b[0m in \u001b[0;36mmake_glm_report\u001b[0;34m(model, contrasts, title, bg_img, threshold, alpha, cluster_threshold, height_control, min_distance, plot_type, display_mode, report_dims)\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0mhtml_design_matrices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_dmtx_to_svg_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdesign_matrices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0mmask_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask_img\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasker_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask_img_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m     mask_plot_html_code = _mask_to_svg(mask_img=mask_img,\n\u001b[0m\u001b[1;32m    204\u001b[0m                                        \u001b[0mbg_img\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbg_img\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m                                        )\n",
      "\u001b[0;32m~/anaconda3/envs/hyruuk_shinobi_behav/lib/python3.8/site-packages/nilearn/reporting/glm_reporter.py\u001b[0m in \u001b[0;36m_mask_to_svg\u001b[0;34m(mask_img, bg_img)\u001b[0m\n\u001b[1;32m    599\u001b[0m     \"\"\"\n\u001b[1;32m    600\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmask_img\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m         mask_plot = plot_roi(roi_img=mask_img,  # noqa: F841\n\u001b[0m\u001b[1;32m    602\u001b[0m                              \u001b[0mbg_img\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbg_img\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m                              \u001b[0mdisplay_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'z'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hyruuk_shinobi_behav/lib/python3.8/site-packages/nilearn/plotting/img_plotting.py\u001b[0m in \u001b[0;36mplot_roi\u001b[0;34m(roi_img, bg_img, cut_coords, output_file, display_mode, figure, axes, title, annotate, draw_cross, black_bg, threshold, alpha, cmap, dim, vmin, vmax, resampling_interpolation, view_type, linewidths, **kwargs)\u001b[0m\n\u001b[1;32m    819\u001b[0m                                                     black_bg=black_bg)\n\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m     display = _plot_img_with_bg(\n\u001b[0m\u001b[1;32m    822\u001b[0m         \u001b[0mimg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mroi_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbg_img\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbg_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcut_coords\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcut_coords\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0moutput_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisplay_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hyruuk_shinobi_behav/lib/python3.8/site-packages/nilearn/plotting/img_plotting.py\u001b[0m in \u001b[0;36m_plot_img_with_bg\u001b[0;34m(img, bg_img, cut_coords, output_file, display_mode, colorbar, figure, axes, title, threshold, annotate, draw_cross, black_bg, vmin, vmax, bg_vmin, bg_vmax, interpolation, display_factory, cbar_vmin, cbar_vmax, brain_color, decimals, **kwargs)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_niimg_3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_safe_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_finite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0maffine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maffine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hyruuk_shinobi_behav/lib/python3.8/site-packages/nilearn/_utils/niimg_conversions.py\u001b[0m in \u001b[0;36mcheck_niimg_3d\u001b[0;34m(niimg, dtype)\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0mIts\u001b[0m \u001b[0mapplication\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0midempotent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m     \"\"\"\n\u001b[0;32m--> 316\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcheck_niimg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mniimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_ndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hyruuk_shinobi_behav/lib/python3.8/site-packages/nilearn/_utils/niimg_conversions.py\u001b[0m in \u001b[0;36mcheck_niimg\u001b[0;34m(niimg, ensure_ndim, atleast_4d, dtype, return_iterator, wildcards)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;31m# Otherwise, it should be a filename or a SpatialImage, we load it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m     \u001b[0mniimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_niimg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mniimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_ndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mniimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mniimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hyruuk_shinobi_behav/lib/python3.8/site-packages/nilearn/_utils/niimg.py\u001b[0m in \u001b[0;36mload_niimg\u001b[0;34m(niimg, dtype)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mniimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnibabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mniimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mniimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnibabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspatialimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSpatialImage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         raise TypeError(\"Data given cannot be loaded because it is\"\n\u001b[0m\u001b[1;32m    122\u001b[0m                         \u001b[0;34m\" not compatible with nibabel format:\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m                         + short_repr(niimg))\n",
      "\u001b[0;31mTypeError\u001b[0m: Data given cannot be loaded because it is not compatible with nibabel format:\nNiftiMasker(mask_i..."
     ]
    }
   ],
   "source": [
    "# Since that worked, let's treat ourselves a quick report\n",
    "fmri_glm.generate_report(contrasts=['LeftH-RightH'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now, let's see how I can (spoiler : can't) reach that same step (i.e. fitted GLM able to generate a fine report) but this time, with the addition of step 1, 2 or 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 : Project the functional images on the anatomical image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NiftiMasker' object has no attribute 'mask_img_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-a3557f2dd613>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m                           mask_img=masker) # don't forget to pass the masker to FLM\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mfmri_glm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfmri_glm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfmri_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLvR_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/hyruuk_shinobi_behav/lib/python3.8/site-packages/nilearn/glm/first_level/first_level.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, run_imgs, events, confounds, design_matrices)\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasker_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_imgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask_img_\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasker_\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasker_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m                 for param_name in ['target_affine', 'target_shape',\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NiftiMasker' object has no attribute 'mask_img_'"
     ]
    }
   ],
   "source": [
    "# 1st try : Build masker from anat_img and pass it to FLM\n",
    "masker = NiftiMasker(anat_fname) # could it be that easy ??\n",
    "\n",
    "\n",
    "fmri_glm = FirstLevelModel(t_r=1.49,\n",
    "                           noise_model='ar1',\n",
    "                           standardize=False,\n",
    "                           hrf_model='spm',\n",
    "                           drift_model='cosine',\n",
    "                           high_pass=.01,\n",
    "                           n_jobs=-1,\n",
    "                           smoothing_fwhm=5,\n",
    "                          mask_img=masker) # don't forget to pass the masker to FLM\n",
    "\n",
    "fmri_glm = fmri_glm.fit(fmri_img, LvR_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok I remember now : if it's too good to be true, it probably is.\n",
    "\n",
    "So, what happened here ? It seems that loading the masker with mask_img=anat_fname does create a mask fitted to the anatomical image, but doesn't transform any data with it. \n",
    "From what I understand, I would expect the transform() step to be performed in the FLM class from the specified masker, that way it can iterate the different runs with the same masker. But that doesn't seem to be the case, so let's try to transform the data beforehand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 2nd try : Build masker from anat_img and pass it to FLM, but fit the data beforehand\n",
    "\n",
    "masker = NiftiMasker(mask_img=anat_fname) # obviously not that easy\n",
    "masker = masker.transform(fmri_img)\n",
    "\n",
    "\n",
    "fmri_glm = FirstLevelModel(t_r=1.49,\n",
    "                           noise_model='ar1',\n",
    "                           standardize=False,\n",
    "                           hrf_model='spm',\n",
    "                           drift_model='cosine',\n",
    "                           high_pass=.01,\n",
    "                           n_jobs=-1,\n",
    "                           smoothing_fwhm=5,\n",
    "                          mask_img=masker) # don't forget to pass the masker to FLM\n",
    "\n",
    "fmri_glm = fmri_glm.fit(fmri_img, LvR_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok so apparently mask_img=anat_fname doesn't even fit the anatomical image on the masker... What does it do then ?\n",
    "That code is probably wrong anyway since I'm transforming the fmri data with the masker, then pass the transformed masker to FLM, then fit the non-transformed data to it... Sound not good at all.\n",
    "\n",
    "So let's try \"intuitively\" cleaning that up by only passing the transformed fmri data to FLM.fit()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 3rd try : Build empty masker, fit with anat_img, transform fmri_img, and pass the transformed fmri_img to FLM.fit()\n",
    "\n",
    "masker = NiftiMasker() # create an empty masker\n",
    "masker = masker.fit(anat_fname) # fit anatomical image\n",
    "fmri_masked = masker.transform(fmri_img) # create transformed fmri data\n",
    "\n",
    "fmri_glm = FirstLevelModel(t_r=1.49,\n",
    "                           noise_model='ar1',\n",
    "                           standardize=False,\n",
    "                           hrf_model='spm',\n",
    "                           drift_model='cosine',\n",
    "                           high_pass=.01,\n",
    "                           n_jobs=-1,\n",
    "                           smoothing_fwhm=5) # no need to pass the mask anymore since we only use the transformed data\n",
    "\n",
    "fmri_glm = fmri_glm.fit(fmri_masked, LvR_df) # pass fmri_masked instead of fmri_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh ! An error message that we've never seen before !\n",
    "\n",
    "![New error message](https://i.imgflip.com/4qnydl.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But, in all seriousness, what does this error really mean ? It sounds like some data shapes were not matching, but it could be something else... \n",
    "Maybe it's because I decided not to pass the masker to FLM ? Let's try this :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 4th try : Same but also pass the masker to FLM\n",
    "\n",
    "masker = NiftiMasker() # create an empty masker\n",
    "masker = masker.fit(anat_fname) # fit anatomical image\n",
    "fmri_masked = masker.transform(fmri_img) # create transformed fmri data\n",
    "\n",
    "fmri_glm = FirstLevelModel(t_r=1.49,\n",
    "                           noise_model='ar1',\n",
    "                           standardize=False,\n",
    "                           hrf_model='spm',\n",
    "                           drift_model='cosine',\n",
    "                           high_pass=.01,\n",
    "                           n_jobs=-1,\n",
    "                           smoothing_fwhm=5,\n",
    "                          mask_img=masker) # mask_img argument is back\n",
    "\n",
    "fmri_glm = fmri_glm.fit(fmri_masked, LvR_df) # pass fmri_masked instead of fmri_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same error... I think I'm running out of ideas about that one.\n",
    "\n",
    "Unless... It is actually so easy that I simply have to give the anat file to mask_img in the FLM call ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4th try : Same but also pass the masker to FLM\n",
    "\n",
    "fmri_glm = FirstLevelModel(t_r=1.49,\n",
    "                           noise_model='ar1',\n",
    "                           standardize=False,\n",
    "                           hrf_model='spm',\n",
    "                           drift_model='cosine',\n",
    "                           high_pass=.01,\n",
    "                           n_jobs=-1,\n",
    "                           smoothing_fwhm=5,\n",
    "                          mask_img=anat_fname) # directly pass the filename of the anatomical image \n",
    "\n",
    "fmri_glm = fmri_glm.fit(fmri_img, LvR_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And I guess that... works...? \n",
    "\n",
    "Let's generate a report to confirm everything went smoothly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmri_glm.generate_report(contrasts=['LeftH-RightH'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much cleaner indeed, looks like that *did* work.\n",
    "Ok, let's forget about the first three attempts, shall we ? ^^'  \n",
    "Lesson learned, clearing my head and my code (and talking to you, awesome rubber duck) really helped me overcome that question. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 : Add confounds from .tsv file\n",
    "\n",
    "Remember : drifts are already computed in the confounds file, so we need to set drift_model=None in FirstLevelModel so they are not computed anew."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by trying to directly pass the confounds_fname to the flm.fit() call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fmri_glm = FirstLevelModel(t_r=1.49,\n",
    "                           noise_model='ar1',\n",
    "                           standardize=False,\n",
    "                           hrf_model='spm',\n",
    "                           drift_model='cosine', # reactivate automatic drift compensation\n",
    "                           high_pass=.01,\n",
    "                           n_jobs=-1,\n",
    "                           smoothing_fwhm=5) # let's make this simple and start without anatomical mask \n",
    "\n",
    "fmri_glm = fmri_glm.fit(fmri_img, LvR_df, confounds=confounds_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weird, afaiu there is a default option in load_confounds() that is supposed to take care of these nasty NaNs.  \n",
    "Let's try again by loading confounds beforehand, who knows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmri_glm = FirstLevelModel(t_r=1.49,\n",
    "                           noise_model='ar1',\n",
    "                           standardize=False,\n",
    "                           hrf_model='spm',\n",
    "                           drift_model='cosine', # reactivate automatic drift compensation\n",
    "                           high_pass=.01,\n",
    "                           n_jobs=-1,\n",
    "                           smoothing_fwhm=5) # let's make this simple and start without anatomical mask \n",
    "\n",
    "confounds = load_confounds.Params36().load(confounds_fname)\n",
    "fmri_glm = fmri_glm.fit(fmri_img, LvR_df, confounds=confounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another error. Not really what I expected either : I thought glm.fit() would call for load_confounds and give the same result as above but it seems not to be the case.  \n",
    "Alright so, according to the [documentation of load_confounds()](https://github.com/SIMEXP/load_confounds), confounds can be \"applied\" to the data by transforming them using a masker object. Let's try that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masker = NiftiMasker()\n",
    "masker.fit(fmri_img)\n",
    "confounds = load_confounds.Params36().load(confounds_fname)\n",
    "fmri_img_conf = masker.transform(fmri_img, confounds=confounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright alright we're getting somewhere ! There is only one thing left to do : running the FLM\n",
    "\n",
    "Note : that warning message might be informative in some way, but I'm not sure yet that it's really problematic for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmri_glm = FirstLevelModel(t_r=1.49,\n",
    "                           noise_model='ar1',\n",
    "                           standardize=False,\n",
    "                           hrf_model='spm',\n",
    "                           drift_model=None, # we already took care of the confounds when transforming the fmri_img\n",
    "                           high_pass=.01,\n",
    "                           n_jobs=-1,\n",
    "                           smoothing_fwhm=5)\n",
    "\n",
    "fmri_glm = fmri_glm.fit(fmri_img_conf, LvR_df) # here we pass the fmri_img that have been transformed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uh-oh, looks like masker.transform() changed the shape of the image ?\n",
    "Actually, according to the [Nilearn documentation](https://nilearn.github.io/modules/generated/nilearn.input_data.NiftiMasker.html), \n",
    "it is expected that the output of masker.transform() should be a 2D matrix. But, previously I was passing a 4D image to FLM and it worked, so let's see if we can go back to 4D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fmri_img.shape) # that's 4D (3D + time)\n",
    "print(fmri_img_conf.shape) # and that's 2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's weird still is that 97 * 97 * 115 =/= 774696\n",
    "\n",
    "But there is a [Nilearn function](https://nilearn.github.io/modules/generated/nilearn.regions.signals_to_img_maps.html) that might be able to help us. Let's try it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.regions import signals_to_img_maps\n",
    "fmri_img_new = signals_to_img_maps(fmri_img_conf, fmri_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No luck, it seems that the difference between the shapes of fmri_img and fmri_img_conf is problematic here too...\n",
    "Still have no clue on how to get back to a 4D Nifti image from the region_signals obtained after masker.transform().\n",
    "\n",
    "I'm not even sure I really need a 4D matrix to input into flm.fit(), but [according to the doc](https://nilearn.github.io/modules/generated/nilearn.glm.first_level.FirstLevelModel.html), it needs to be a Niimg-like object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm out of ideas for now... Let's see what we're able to do about Step 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 : Hand regressors filtering and normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we have much more Left Hand than Right Hand trials, that means that the Left/Right hand regressors will have widely different aplitudes. To take care of that, Pierre recommends to high-pass filter and zero-mean both hand regressors, which will make the betas comparable.  \n",
    "To do that, I need to find the time series corresponding to the hand regressors, process them and input them back in the model.  \n",
    "  \n",
    "The first obstacle I see in doing that is that up 'til now, I was directly passing the events_df to the model and letting the object take care of creating the regressors. Can't do that anymore, so I'll need to (1) create/extract hand regressors and (2) find a way to input timeseries regressors instead of events dataframes in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, instead of passing the events_df, I want to manually [create the design matrices](https://nilearn.github.io/modules/generated/nilearn.glm.first_level.make_first_level_design_matrix.html#nilearn.glm.first_level.make_first_level_design_matrix) :\n",
    "\n",
    "I need two arguments : events_df and frame_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nilearn\n",
    "t_r = 1.49\n",
    "n_slices = fmri_img.shape[-1]\n",
    "frame_times = np.arange(n_slices) * t_r\n",
    "\n",
    "design_matrix = nilearn.glm.first_level.make_first_level_design_matrix(frame_times, \n",
    "                                                                       events=LvR_df,\n",
    "                                                                      drift_model='cosine') # note, there will probably be something to do about that when the confounds will be added\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from nistats.reporting import plot_design_matrix\n",
    "plot_design_matrix(design_matrix)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are our regressors ! \n",
    "Let's process them and see how that affects the two timeseries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LeftH_ts = np.asarray(design_matrix['LeftH'])\n",
    "RightH_ts = np.asarray(design_matrix['RightH'])\n",
    "\n",
    "plt.plot(LeftH_ts)\n",
    "plt.plot(RightH_ts)\n",
    "plt.xlabel('scan')\n",
    "plt.title('Expected Response')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "\n",
    "b, a = signal.butter(3, 0.01, btype='high')\n",
    "\n",
    "\n",
    "plt.plot(signal.filtfilt(b, a, LeftH_ts))\n",
    "plt.plot(signal.filtfilt(b, a, RightH_ts))\n",
    "plt.xlabel('scan')\n",
    "plt.title('Expected Response (filtered)')\n",
    "plt.show()\n",
    "\n",
    "LeftH_ts_hpf = signal.filtfilt(b, a, LeftH_ts)\n",
    "RightH_ts_hpf = signal.filtfilt(b, a, RightH_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "\n",
    "\n",
    "plt.plot(zscore(LeftH_ts_hpf))\n",
    "plt.plot(zscore(RightH_ts_hpf))\n",
    "plt.xlabel('scan')\n",
    "plt.title('Expected Response (filtered + zscore)')\n",
    "plt.show()\n",
    "\n",
    "LeftH_ts_hpf_z = zscore(LeftH_ts_hpf)\n",
    "RightH_ts_hpf_z = zscore(RightH_ts_hpf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect. Now we just have to input that back in the design matrix and run the model !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "design_matrix['LeftH'] = LeftH_ts_hpf_z\n",
    "design_matrix['RightH'] = RightH_ts_hpf_z\n",
    "\n",
    "fmri_glm = FirstLevelModel(t_r=1.49,\n",
    "                           noise_model='ar1',\n",
    "                           standardize=False,\n",
    "                           hrf_model='spm',\n",
    "                           drift_model='cosine',\n",
    "                           high_pass=.01,\n",
    "                           n_jobs=-1,\n",
    "                           smoothing_fwhm=5,\n",
    "                          mask_img=anat_fname) # directly pass the filename of the anatomical image \n",
    "\n",
    "fmri_glm = fmri_glm.fit(fmri_img, design_matrices=design_matrix)\n",
    "fmri_glm.generate_report(contrasts=['LeftH-RightH'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus step : link the three previous steps together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of the rubber duck\n",
    "Beware, the cells below are nothing more than a messy dump of potentially useful bits of code. No need to look further, proceed at your own risk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masker = NiftiMasker(mask_img=anat_fname)\n",
    "confounds = load_confounds.Params36().load(confounds_fname)\n",
    "masked_img = masker.fit_transform(fmri_img, confounds=confounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confounds = load_confounds.Params36().load(confounds_fname)\n",
    "masker = NiftiMasker()\n",
    "masker = masker.fit(fmri_img)\n",
    "masked_img = masker.transform(fmri_img, confounds=confounds)\n",
    "fmri_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = fmri_glm.generate_report(contrasts=['LeftH-RightH'])\n",
    "report.save_as_html('/home/hyruuk/GitHub/neuromod/hyruuk_shinobi_behav/reports/sub-01_ses-01_flm.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masker.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build GLM\n",
    "from nilearn.glm.first_level import FirstLevelModel\n",
    "fmri_glm = FirstLevelModel(t_r=1.49,\n",
    "                           noise_model='ar1',\n",
    "                           standardize=False,\n",
    "                           hrf_model='spm',\n",
    "                           drift_model='cosine',\n",
    "                           high_pass=.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit\n",
    "fmri_glm = fmri_glm.fit(fmri_img, LvR_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create design_matrix\n",
    "design_matrix = fmri_glm.design_matrices_[0]\n",
    "\n",
    "# Plot\n",
    "from nilearn.plotting import plot_design_matrix\n",
    "plot_design_matrix(design_matrix)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot convoluted regressors\n",
    "plt.plot(design_matrix['LeftH'], label='LeftH')\n",
    "plt.plot(design_matrix['RightH'], label='RightH')\n",
    "\n",
    "plt.xlabel('scan')\n",
    "plt.title('Expected BOLD response')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'Nifti1Image' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-f10e1979647d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfmri_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'Nifti1Image' has no len()"
     ]
    }
   ],
   "source": [
    "len(fmri_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "409"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(confounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create condition arrays\n",
    "from numpy import array\n",
    "conditions = {\n",
    "    'LeftH': array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
    "    'RightH':   array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subtract conditions\n",
    "left_minus_right = conditions['LeftH'] - conditions['RightH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot contrast\n",
    "from nilearn.plotting import plot_contrast_matrix\n",
    "plot_contrast_matrix(left_minus_right, design_matrix=design_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z score maps\n",
    "\n",
    "z_map = fmri_glm.compute_contrast(['LeftH-RightH'],\n",
    "                                    output_type='z_score', stat_type='F')\n",
    "plotting.plot_stat_map(z_map, bg_img=mean_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z threshold\n",
    "\n",
    "plotting.plot_stat_map(z_map, bg_img=mean_img, threshold=3.0,\n",
    "              display_mode='z', cut_coords=3, black_bg=True,\n",
    "              title='Left minus Right Hand (Z>3)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncorrected\n",
    "\n",
    "from nistats.thresholding import map_threshold\n",
    "uncorr_001, threshold = map_threshold(z_map, alpha=.001, height_control='fpr')\n",
    "print('Uncorrected p<0.001 threshold: %.3f' % threshold)\n",
    "plotting.plot_stat_map(z_map, bg_img=mean_img, threshold=threshold,\n",
    "              display_mode='z', cut_coords=3, black_bg=True,\n",
    "              title='Left minus Right Hand (p<0.001)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FDR only\n",
    "\n",
    "_, threshold = map_threshold(z_map, alpha=.05, height_control='fdr')\n",
    "\n",
    "print('Taux de fausse découverte (FDR) = 0.05 threshold: %.3f' % threshold)\n",
    "\n",
    "plotting.plot_stat_map(z_map, bg_img=mean_img, threshold=threshold,\n",
    "              display_mode='z', cut_coords=3, black_bg=True,\n",
    "              title='sub-01, ses-008, run-01, Left minus Right Hand (fdr=0.05)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FDR + clusters\n",
    "\n",
    "clean_map, threshold = map_threshold(z_map, alpha=.05, height_control='fdr', cluster_threshold=10)\n",
    "\n",
    "plotting.plot_stat_map(clean_map, bg_img=mean_img, threshold=threshold,\n",
    "              display_mode='z', cut_coords=3, black_bg=True,\n",
    "              title='Left minus Right Hand (FDR=0.05), Noyaux > 10 voxels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save interactive plot\n",
    "view = plotting.view_img(clean_map, threshold=3, title='Left minus Right Hand (FDR=0.05), Noyaux > 10 voxels')\n",
    "view.save_as_html(figures_path + '/LmR_statsmap.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set constants for MULTIPLE RUNS\n",
    "sub = 'sub-01'\n",
    "actions = ['B', 'A', 'MODE', 'START', 'UP', 'DOWN', 'LEFT', 'RIGHT', 'C', 'Y', 'X', 'Z']\n",
    "dpath = '/media/hyruuk/Seagate Expansion Drive/DATA/data/shinobi/'\n",
    "\n",
    "\n",
    "\n",
    "seslist= os.listdir(dpath + sub)\n",
    "\n",
    "allruns_events = []\n",
    "fmri_img = []\n",
    "for ses in ['ses-001']:#sorted(seslist):\n",
    "    runs = [filename[-13] for filename in os.listdir(dpath + '{}/{}/func'.format(sub, ses)) if 'bold.nii.gz' in filename]\n",
    "    print(runs)\n",
    "    for run in sorted(runs):\n",
    "        print('computing run {}'.format(run))\n",
    "        events_fname = dpath + '{}/{}/func/{}_{}_task-shinobi_run-0{}_events.tsv'.format(sub, ses, sub, ses, run)\n",
    "        filename = dpath + 'derivatives/fmriprep-20.2lts/fmriprep/{}/{}/func/sub-01_{}_task-shinobi_run-{}_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz'.format(sub, ses, ses, run)\n",
    "        confounds_fname = dpath + 'derivatives/fmriprep-20.2lts/fmriprep/{}/{}/func/sub-01_{}_task-shinobi_run-{}_desc-confounds_timeseries.tsv'.format(sub, ses, ses, run)\n",
    "        # Obtain list of bk2 files from events\n",
    "        startevents = pd.read_table(events_fname)\n",
    "        files = startevents['stim_file'].values.tolist()\n",
    "        files = [dpath + file for file in files]\n",
    "\n",
    "        # Retrieve variables from these files\n",
    "        runvars = retrieve_variables(files)\n",
    "        events_df = create_runevents(runvars, startevents, actions=actions)\n",
    "        events_df['trial_type'].unique()\n",
    "\n",
    "        # Create LvR_df\n",
    "        lh_df = pd.concat([events_df[events_df['trial_type'] == '1_LEFT'], \n",
    "                           events_df[events_df['trial_type'] == '1_RIGHT'],\n",
    "                           events_df[events_df['trial_type'] == '1_DOWN'],\n",
    "                           events_df[events_df['trial_type'] == '1_UP'],\n",
    "                           events_df[events_df['trial_type'] == '4_LEFT'], \n",
    "                           events_df[events_df['trial_type'] == '4_RIGHT'],\n",
    "                           events_df[events_df['trial_type'] == '4_DOWN'],\n",
    "                           events_df[events_df['trial_type'] == '4_UP'],\n",
    "                            events_df[events_df['trial_type'] == '5_LEFT'], \n",
    "                           events_df[events_df['trial_type'] == '5_RIGHT'],\n",
    "                           events_df[events_df['trial_type'] == '5_DOWN'],\n",
    "                           events_df[events_df['trial_type'] == '5_UP']\n",
    "                          ]).sort_values(by='onset').reset_index(drop=True)\n",
    "        lh_df['trial_type'] = 'LeftH'\n",
    "        rh_df = pd.concat([events_df[events_df['trial_type'] == '1_B'], \n",
    "                           events_df[events_df['trial_type'] == '1_C'],\n",
    "                           events_df[events_df['trial_type'] == '4_B'], \n",
    "                           events_df[events_df['trial_type'] == '4_C'],\n",
    "                            events_df[events_df['trial_type'] == '5_B'], \n",
    "                           events_df[events_df['trial_type'] == '5_C']\n",
    "                          ]).sort_values(by='onset').reset_index(drop=True)\n",
    "        rh_df['trial_type'] = 'RightH'\n",
    "        LvR_df = pd.concat([lh_df, rh_df]).sort_values(by='onset').reset_index(drop=True)\n",
    "        \n",
    "        allruns_events.append(LvR_df)\n",
    "        \n",
    "        confounds = load_confounds.Params36().load(confounds_fname)\n",
    "        masker = NiftiMasker()\n",
    "        masker.fit(filename)\n",
    "        \n",
    "        masked_img = masker.transform(filename, confounds=confounds)\n",
    "        fmri_img.append(masked_img)\n",
    "\n",
    "        \n",
    "#import pickle\n",
    "#with open(dpath + '{}_events_files.pkl'.format(sub), 'wb') as f:\n",
    "#    pickle.dump(allruns_events, f)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.glm.first_level import FirstLevelModel\n",
    "print('Fitting a GLM')\n",
    "fmri_glm = FirstLevelModel(t_r=1.49,\n",
    "                           noise_model='ar1',\n",
    "                           standardize=False,\n",
    "                           hrf_model='spm',\n",
    "                           drift_model='cosine',\n",
    "                           high_pass=.01,\n",
    "                           n_jobs=-1,\n",
    "                           smoothing_fwhm=5)\n",
    "fmri_glm = fmri_glm.fit(fmri_img, allruns_events)\n",
    "\n",
    "\n",
    "mean_img = image.mean_img(fmri_img)\n",
    "plotting.plot_img(mean_img, title='Image de fond (T2* - BOLD)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_map = fmri_glm.compute_contrast(['LeftH-RightH'] * len(fmri_img), \n",
    "    output_type='z_score', stat_type='F')\n",
    "\n",
    "plotting.plot_stat_map(z_map, bg_img=mean_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nistats.thresholding import map_threshold\n",
    "\n",
    "clean_map, threshold = map_threshold(z_map, alpha=.05, height_control='fdr', cluster_threshold=10)\n",
    "uncorr_map, threshold = map_threshold(z_map, alpha=.001, height_control='fpr')\n",
    "\n",
    "\n",
    "plotting.plot_stat_map(clean_map, bg_img=mean_img, threshold=threshold,\n",
    "              display_mode='z', cut_coords=3, black_bg=True,\n",
    "              title='Left minus Right Hand (FDR=0.05), Noyaux > 10 voxels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view = plotting.view_img(clean_map, threshold=3, title='Left minus Right Hand (FDR=0.05), Noyaux > 10 voxels')\n",
    "view.save_as_html(figures_path + '/{}_LmR_statsmap_allruns_FDRcluster.html'.format(sub))\n",
    "\n",
    "view = plotting.view_img(clean_map, threshold=3, title='Left minus Right Hand (p<0.001), uncorr')\n",
    "view.save_as_html(figures_path + '/{}_LmR_statsmap_allruns_uncorr.html'.format(sub))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.plotting import plot_design_matrix\n",
    "plot_design_matrix(fmri_glm.design_matrices_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['LeftH-RightH'] * len(fmri_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bids import BIDSLayout\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpath = '/media/hyruuk/Seagate Expansion Drive/DATA/data/shinobi/derivatives/fmriprep-20.2lts/fmriprep'\n",
    "\n",
    "layout = BIDSLayout(dpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masker = NiftiMasker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = masker.transform(file, confounds=confounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hyruuk_shinobi_behav",
   "language": "python",
   "name": "hyruuk_shinobi_behav"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
